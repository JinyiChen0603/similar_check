# 移植建议

本文档记录当前项目的功能实现、所用语句与逻辑，以及移植到已有网站时应采用的方法与函数。

---

## 一、功能总览

| 功能 | 入口/脚本 | 核心逻辑所在文件 |
|------|-----------|------------------|
| 题干查重（是否与已用题目重复） | `check_duplicate.py` | `duplicate_logic.py` |
| 题目+解析+答案相似度比较与报告 | `similarity_report.py` | `duplicate_logic.py` + `similarity_report.py` |
| 从 CSV/XLSX 导入题目到 JSON | `import_testquestion.py` | `import_testquestion.py` |

---

## 二、题干查重（与已用题目是否重复）

### 2.1 实现了什么

- 输入：一道题的**题干文本**。
- 行为：与数据库中「已用题目」列表逐条比较相似度；相似度 ≥ 阈值则视为重复。
- 输出：`is_duplicate`（是否重复）、`matches`（匹配到的已用题目列表，含 id、题干、相似度，最多 10 条）。

### 2.2 使用的语句与逻辑

**文件：`duplicate_logic.py`**

1. **取已用题目**（第 10–14 行）  
   - `get_used_questions(conn)`：执行 SQL  
     `SELECT id, content FROM questions WHERE used = 1 ORDER BY id`  
   - 返回 `[(id, content), ...]`。

2. **计算两段文本相似度**（第 17–24 行）  
   - `compute_similarity(text_a, text_b)`：  
     - 对空串做边界处理（两空→1.0，一空→0.0）。  
     - 使用 `difflib.SequenceMatcher(None, a, b).ratio()` 得到 0~1 的相似度。

3. **查重判断**（第 69–101 行）  
   - `check_duplicate(question_text, conn, threshold=0.75, exclude_id=None)`：  
     - 调用 `get_used_questions(conn)` 得到已用题目列表。  
     - 遍历每条：若 `exclude_id` 等于当前 id 则跳过；否则 `sim = compute_similarity(question_text, used_text)`。  
     - **判断**：`if sim >= threshold` 则加入 `matches`。  
     - 按相似度降序排序，取前 10 条。  
     - 返回 `{"is_duplicate": len(matches) > 0, "matches": matches[:10]}`。

### 2.3 移植时采用的方法

| 场景 | 采用方法 | 说明 |
|------|----------|------|
| **只算两道题干是否相似** | `compute_similarity(text_a, text_b)` | 纯函数，仅依赖 `difflib`，直接拷贝 17–24 行即可。 |
| **“新题是否与已用题重复”的完整逻辑** | `check_duplicate` 的**内部逻辑** | 保留：遍历已用列表 → 对每条 `compute_similarity` → `sim >= threshold` 则视为重复。 |
| **数据源** | 替换 `get_used_questions` | 原实现依赖 SQLite 与本地表结构；移植时改为从你的网站 DB/API 取「已用题目」列表，格式为 `[(id, content), ...]`。 |

**可移植函数**：`compute_similarity`（17–24 行）、`check_duplicate` 的算法部分（85–101 行，但入参中的 `conn` 改为你提供的「已用题目列表」或封装成你后端的接口）。

---

## 三、题目 + 解析 + 答案 相似度比较与报告

### 3.1 实现了什么

- 输入：题目列表（每题为 dict：`content`、`explanation`、`answer`）。
- 行为：两两比较，对每对计算「题目相似度」「解析相似度」「答案相似度」和「综合相似度」；报告里只输出综合相似度 ≥ 某阈值的题目对。
- 输出：命令行打印每对的四类相似度及题干摘要；也可指定「与第 N 题比较」只输出与某一题的所有相似度。

### 3.2 使用的语句与逻辑

**文件：`duplicate_logic.py`**

1. **两道题的多维相似度**（第 27–65 行）  
   - `compute_question_similarity(q_a, q_b, weight_content=0.5, weight_explanation=0.3, weight_answer=0.2)`：  
     - 从 `q_a`、`q_b` 取出 `content`、`explanation`、`answer`（缺省用空串），strip。  
     - 分别调用 `compute_similarity` 得到 `sim_content`、`sim_explanation`、`sim_answer`。  
     - 综合：`overall = weight_content * sim_content + weight_explanation * sim_explanation + weight_answer * sim_answer`。  
     - 返回 `{"content": round(..., 4), "explanation": ..., "answer": ..., "overall": ...}`。

**文件：`similarity_report.py`**

2. **是否输出某一对**（第 22–33 行）  
   - `report_pair(i, j, q_a, q_b, threshold)`：  
     - `sim = compute_question_similarity(q_a, q_b)`。  
     - **判断**：`if sim["overall"] < threshold: return`（低于阈值则不打印）。  
     - 否则打印题目/解析/答案/综合相似度及题干摘要。

3. **两两比较流程**（第 36–68 行）  
   - 从 `questions.json` 读取题目列表。  
   - 若命令行传入题目序号：只对该题与其余每题调用 `report_pair(..., threshold=0)`（全部输出）。  
   - 否则：对所有 `i < j` 调用 `report_pair(i, j, questions[i], questions[j], threshold=0.3)`，只输出综合相似度 ≥ 30% 的对。

### 3.3 移植时采用的方法

| 场景 | 采用方法 | 说明 |
|------|----------|------|
| **两道题的题目/解析/答案相似度 + 综合分** | `compute_question_similarity(q_a, q_b)` | 纯函数，只依赖 `compute_similarity` 和 dict 结构；直接拷贝 27–65 行（并保留 `compute_similarity`）。 |
| **“相似题推荐/报告”的筛选逻辑** | `sim["overall"] >= threshold` | 与 `similarity_report.py` 第 25–26 行一致：先算 `compute_question_similarity`，再按综合相似度是否 ≥ 阈值决定是否展示。 |
| **题目数据来源** | 替换 `load_questions()` | 原实现读本地 `questions.json`；移植时改为从你的 API/DB 取题目列表，每题为 `{ "content", "explanation", "answer" }`。 |

**可移植函数**：`compute_similarity`（17–24 行）、`compute_question_similarity`（27–65 行）。报告展示与数据加载按你网站的前端/后端方式重写即可。

---

## 四、从 CSV/XLSX 导入题目

### 4.1 实现了什么

- 在项目目录查找 `testquestion.csv` 或 `testquestion.xlsx`，按列名「相似题目」「解析」「答案」解析（无则用「题目」当题干列）。
- 将每行转为 `{ "content", "answer", "explanation" }`，追加到 `questions.json`。

### 4.2 使用的语句与逻辑

**文件：`import_testquestion.py`**

- CSV：`csv.DictReader`，按列名取「相似题目」/「题目」「解析」「答案」；题干非空则追加一条。
- XLSX：`openpyxl` 读首行作表头，按表头含「相似题目」/「题目」「解析」「答案」确定列下标，再遍历数据行组合同一结构。
- 最后：`load_questions_json()` 读出现有列表，`existing.extend(new_items)`，`save_questions_json(existing)` 写回。

### 4.3 移植时采用的方法

| 场景 | 说明 |
|------|------|
| **网站已有题目录入/导入** | 一般不需要移植此脚本；只需保证题目在 DB/API 中具有 `content`、`explanation`、`answer` 字段（或等价字段），供上面相似度与查重逻辑使用。 |
| **仍需从 Excel/CSV 批量导入** | 可参考 `load_csv` / `load_xlsx` 的列名映射与 `{ content, answer, explanation }` 的构造方式，在你的后端实现「上传文件 → 解析 → 写入你的数据库」的接口。 |

移植重点在**数据结构**：保证题目对象包含 `content`、`explanation`、`answer`（或你映射后的键名），并在调用 `compute_question_similarity` / `compute_similarity` 时使用同一键名。

---

## 五、移植时建议拷贝的代码清单

| 用途 | 文件 | 行号 | 函数/逻辑 | 依赖 |
|------|------|------|------------|------|
| 两段文本相似度 | `duplicate_logic.py` | 17–24 | `compute_similarity(text_a, text_b)` | `import difflib` |
| 两道题题目/解析/答案+综合相似度 | `duplicate_logic.py` | 27–65 | `compute_question_similarity(q_a, q_b, ...)` | 上者 + dict 含 `content`/`explanation`/`answer` |
| 题干查重（与已用题列表比较） | `duplicate_logic.py` | 85–101 | `check_duplicate` 内部：遍历 → `compute_similarity` → `sim >= threshold` → 排序截断 | 已用题目列表 `[(id, content), ...]` 由你方提供 |

**不需要移植**：`get_used_questions`、`get_db_connection`、`DB_PATH`（依赖本地 SQLite）；`similarity_report.py` 的 `load_questions`、`QUESTIONS_JSON`、`print` 输出（改为你网站的数据源与展示方式）。

---

## 六、数据约定（便于移植）

- **单道题目**：`{ "content": "题干", "answer": "答案", "explanation": "解析" }`，键可缺省，按空串处理。
- **查重入参**：题干字符串；已用题目列表为 `[(id, content), ...]`。
- **相似度数值**：均为 0~1，四舍五入到 4 位小数；综合相似度为加权和，权重默认题目 0.5、解析 0.3、答案 0.2。

按上述方法与函数移植，即可在已有网站复现题干查重与题目/解析/答案相似度比较功能。
